{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvamsi91/RTML_AS5/blob/main/RTML_AS534.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaCODuFh4U70"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_to_french = [\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\")\n",
        "]"
      ],
      "metadata": {
        "id": "kEIzg9c74dzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define tokens to signify the start and end of sequences\n",
        "SOS_token, EOS_token = 0, 1\n",
        "\n",
        "# Assume english_to_french dataset exists; create reversed pairs for training\n",
        "french_to_english = [(french, english) for english, french in english_to_french]\n",
        "\n",
        "# Map all unique words to indices, including special tokens\n",
        "word_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token}\n",
        "for source, target in french_to_english:\n",
        "    for word in source.split() + target.split():\n",
        "        if word not in word_to_index:\n",
        "            word_to_index[word] = len(word_to_index)\n",
        "\n",
        "# Dataset class for translation using indexed word representation\n",
        "class TranslationDataset(Dataset):\n",
        "    \"\"\"Manages French to English translation pairs.\"\"\"\n",
        "    def __init__(self, data, index_map):\n",
        "        self.data = data\n",
        "        self.index_map = index_map\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the count of data pairs\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert sentences to indices, append EOS, and return as tensors\n",
        "        source, target = self.data[idx]\n",
        "        source_indices = [self.index_map[word] for word in source.split()] + [EOS_token]\n",
        "        target_indices = [self.index_map[word] for word in target.split()] + [EOS_token]\n",
        "        return torch.tensor(source_indices, dtype=torch.long), torch.tensor(target_indices, dtype=torch.long)\n",
        "\n",
        "# Example DataLoader setup for training\n",
        "# dataset = TranslationDataset(french_to_english, word_to_index)\n",
        "# loader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "vRyGcC_74sOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    inputs, targets = zip(*batch)\n",
        "    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=EOS_token)\n",
        "    padded_targets = pad_sequence(targets, batch_first=True, padding_value=EOS_token)\n",
        "    return padded_inputs, padded_targets\n",
        "\n",
        "# Transformer-based model for language translation tasks\n",
        "class TranslationModel(nn.Module):\n",
        "    \"\"\"A Transformer model for sequence-to-sequence learning.\"\"\"\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers=4, num_heads=8, dropout=0.1):\n",
        "        super(TranslationModel, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=hidden_size,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dim_feedforward=hidden_size * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True  # Specifies that the batch dimension is the first dimension\n",
        "        )\n",
        "        self.final_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_embedded = self.embed(src)\n",
        "        tgt_embedded = self.embed(tgt)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "        transformer_out = self.transformer(src_embedded, tgt_embedded, tgt_mask=tgt_mask)\n",
        "        final_output = self.final_layer(transformer_out)\n",
        "        return final_output"
      ],
      "metadata": {
        "id": "LXMMnpdK5Qfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, dataloader, optimizer, criterion, epochs, device):\n",
        "    \"\"\"Train and evaluate the model across a specified number of epochs.\"\"\"\n",
        "    for epoch in range(epochs+1):\n",
        "        model.train()  # Set model to training mode\n",
        "        total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, targets[:, :-1])\n",
        "            outputs_flat = outputs.view(-1, outputs.size(-1))\n",
        "            targets_flat = targets[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            # Calculate loss excluding the EOS token\n",
        "            valid_targets_mask = targets_flat != EOS_token\n",
        "            loss = criterion(outputs_flat[valid_targets_mask], targets_flat[valid_targets_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(outputs_flat, 1)\n",
        "            correct_preds = (preds == targets_flat) & valid_targets_mask\n",
        "            total_correct += correct_preds.sum().item()\n",
        "            total_samples += valid_targets_mask.sum().item()\n",
        "\n",
        "        # Logging the training results\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
        "\n",
        "        # Evaluation phase with model in evaluation mode\n",
        "        model.eval()\n",
        "        eval_loss, eval_correct, eval_samples = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs, targets[:, :-1])\n",
        "                outputs_flat = outputs.view(-1, outputs.size(-1))\n",
        "                targets_flat = targets[:, 1:].contiguous().view(-1)\n",
        "\n",
        "                valid_targets_mask = targets_flat != EOS_token\n",
        "                loss = criterion(outputs_flat[valid_targets_mask], targets_flat[valid_targets_mask])\n",
        "                eval_loss += loss.item()\n",
        "                _, preds = torch.max(outputs_flat, 1)\n",
        "                correct_preds = (preds == targets_flat) & valid_targets_mask\n",
        "                eval_correct += correct_preds.sum().item()\n",
        "                eval_samples += valid_targets_mask.sum().item()\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        eval_avg_loss = eval_loss / len(dataloader)\n",
        "        eval_accuracy = eval_correct / eval_samples if eval_samples > 0 else 0\n",
        "\n",
        "        # Print results periodically\n",
        "        if epoch % 5 == 0 :\n",
        "            print(f'Epoch {epoch}: Train Loss = {avg_loss:.4f}, Accuracy = {accuracy:.4f}, '\n",
        "                  f'Eval Loss = {eval_avg_loss:.4f}, Eval Accuracy = {eval_accuracy:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "-C9RzrI46DjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the environment and model parameters\n",
        "vocab_size = len(word_to_index)\n",
        "hidden_size = 64\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TranslationModel(vocab_size, hidden_size).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"EOS\"])\n",
        "\n",
        "# Initialize DataLoader for handling the dataset\n",
        "dataset = TranslationDataset(english_to_french, word_to_index)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "# Execute training and evaluation for the model\n",
        "train_and_evaluate(model, dataloader, optimizer, criterion, 50, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw35rARe6iMg",
        "outputId": "7705b2dd-b8c3-4856-c989-9dfa322b9c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss = 5.9007, Accuracy = 0.0134, Eval Loss = 5.6278, Eval Accuracy = 0.0638\n",
            "Epoch 5: Train Loss = 5.0578, Accuracy = 0.1074, Eval Loss = 4.8524, Eval Accuracy = 0.0973\n",
            "Epoch 10: Train Loss = 4.4069, Accuracy = 0.1477, Eval Loss = 4.1166, Eval Accuracy = 0.2081\n",
            "Epoch 15: Train Loss = 3.7548, Accuracy = 0.3121, Eval Loss = 3.3862, Eval Accuracy = 0.3591\n",
            "Epoch 20: Train Loss = 3.2297, Accuracy = 0.3893, Eval Loss = 2.7517, Eval Accuracy = 0.5470\n",
            "Epoch 25: Train Loss = 2.6662, Accuracy = 0.5940, Eval Loss = 2.2097, Eval Accuracy = 0.7282\n",
            "Epoch 30: Train Loss = 2.1611, Accuracy = 0.7148, Eval Loss = 1.6601, Eval Accuracy = 0.8456\n",
            "Epoch 35: Train Loss = 1.7365, Accuracy = 0.8389, Eval Loss = 1.2626, Eval Accuracy = 0.9430\n",
            "Epoch 40: Train Loss = 1.4150, Accuracy = 0.8725, Eval Loss = 0.9720, Eval Accuracy = 0.9832\n",
            "Epoch 45: Train Loss = 1.0852, Accuracy = 0.9664, Eval Loss = 0.7221, Eval Accuracy = 0.9966\n",
            "Epoch 50: Train Loss = 0.9017, Accuracy = 0.9799, Eval Loss = 0.5386, Eval Accuracy = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "vocab_size = len(word_to_index)\n",
        "hidden_size = 64\n",
        "model = TranslationModel(vocab_size, hidden_size).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"EOS\"])\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = TranslationDataset(french_to_english, word_to_index)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "# Train and evaluate\n",
        "train_and_evaluate(model, dataloader, optimizer, criterion, 100, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90LGBqhHC59p",
        "outputId": "5a0b4650-b374-4f8d-a353-9d5c85fb3712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss = 6.0108, Accuracy = 0.0037, Eval Loss = 5.7182, Eval Accuracy = 0.0769\n",
            "Epoch 5: Train Loss = 5.3420, Accuracy = 0.0916, Eval Loss = 5.1597, Eval Accuracy = 0.0952\n",
            "Epoch 10: Train Loss = 4.8479, Accuracy = 0.1099, Eval Loss = 4.6396, Eval Accuracy = 0.1319\n",
            "Epoch 15: Train Loss = 4.3997, Accuracy = 0.1905, Eval Loss = 4.0844, Eval Accuracy = 0.2198\n",
            "Epoch 20: Train Loss = 3.9467, Accuracy = 0.2308, Eval Loss = 3.5940, Eval Accuracy = 0.3736\n",
            "Epoch 25: Train Loss = 3.6494, Accuracy = 0.3846, Eval Loss = 3.2519, Eval Accuracy = 0.4689\n",
            "Epoch 30: Train Loss = 3.2580, Accuracy = 0.4396, Eval Loss = 2.8375, Eval Accuracy = 0.6117\n",
            "Epoch 35: Train Loss = 2.9553, Accuracy = 0.5238, Eval Loss = 2.5574, Eval Accuracy = 0.6740\n",
            "Epoch 40: Train Loss = 2.6735, Accuracy = 0.6337, Eval Loss = 2.2113, Eval Accuracy = 0.7436\n",
            "Epoch 45: Train Loss = 2.4002, Accuracy = 0.7033, Eval Loss = 1.9001, Eval Accuracy = 0.8059\n",
            "Epoch 50: Train Loss = 2.1528, Accuracy = 0.7289, Eval Loss = 1.6805, Eval Accuracy = 0.8498\n",
            "Epoch 55: Train Loss = 1.9216, Accuracy = 0.8205, Eval Loss = 1.5087, Eval Accuracy = 0.8791\n",
            "Epoch 60: Train Loss = 1.7307, Accuracy = 0.8388, Eval Loss = 1.2605, Eval Accuracy = 0.9048\n",
            "Epoch 65: Train Loss = 1.5234, Accuracy = 0.8755, Eval Loss = 1.0562, Eval Accuracy = 0.9524\n",
            "Epoch 70: Train Loss = 1.3775, Accuracy = 0.9158, Eval Loss = 0.9100, Eval Accuracy = 0.9597\n",
            "Epoch 75: Train Loss = 1.1970, Accuracy = 0.9341, Eval Loss = 0.7967, Eval Accuracy = 0.9780\n",
            "Epoch 80: Train Loss = 1.0587, Accuracy = 0.9377, Eval Loss = 0.6630, Eval Accuracy = 0.9890\n",
            "Epoch 85: Train Loss = 0.8893, Accuracy = 0.9744, Eval Loss = 0.5618, Eval Accuracy = 0.9963\n",
            "Epoch 90: Train Loss = 0.8342, Accuracy = 0.9817, Eval Loss = 0.4628, Eval Accuracy = 0.9963\n",
            "Epoch 95: Train Loss = 0.7340, Accuracy = 0.9817, Eval Loss = 0.3945, Eval Accuracy = 1.0000\n",
            "Epoch 100: Train Loss = 0.6415, Accuracy = 0.9927, Eval Loss = 0.3296, Eval Accuracy = 1.0000\n"
          ]
        }
      ]
    }
  ]
}